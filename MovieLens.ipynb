{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collaborative Filtering ALS Recommender System using Spark MLlib adapted from\n",
    "the Spark Summit 2014 Recommender System training example.\n",
    "\n",
    "Developed By: Pranav Masariya\n",
    "Supervisor: Dr. Magdalini Eirinaki\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.ml.recommendation import ALS as mlals\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import math\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calling spark session to register application\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Recom\") \\\n",
    "    .config(\"spark.recom.demo\", \"1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading and Parsing Dataset\n",
    "    Each line in the ratings dataset (ratings-1.csv) is formatted as:\n",
    "         userId,movieId,rating\n",
    "    Each line in the movies (movies.csv) dataset is formatted as:\n",
    "        movieId,title\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "# Load ratings\n",
    "ratings_df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"ratings-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: int]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|   149|      2|     5|\n",
      "|   149|      3|     3|\n",
      "|   149|      5|     3|\n",
      "|   149|      7|     2|\n",
      "|   149|      9|     4|\n",
      "|   149|     10|     4|\n",
      "|   149|     11|     4|\n",
      "|   149|     12|     4|\n",
      "|   149|     13|     4|\n",
      "|   149|     14|     3|\n",
      "|   149|     16|     5|\n",
      "|   149|     18|     4|\n",
      "|   149|     20|     5|\n",
      "|   149|     21|     4|\n",
      "|   969|      5|     5|\n",
      "|   969|     14|     3|\n",
      "|   969|     15|     1|\n",
      "|   969|     16|     1|\n",
      "|   969|     21|     2|\n",
      "|   589|      1|     4|\n",
      "|   589|      2|     5|\n",
      "|   589|      3|     5|\n",
      "|   589|      4|     4|\n",
      "|   589|      5|     3|\n",
      "|   589|      6|     3|\n",
      "|   589|      7|     2|\n",
      "|   589|      8|     4|\n",
      "|   589|      9|     5|\n",
      "|   589|     10|     5|\n",
      "|   589|     11|     3|\n",
      "+------+-------+------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For the simplicity of this tutorial\n",
    "    For each line in the ratings dataset, we create a tuple of (UserID, MovieID, Rating). \n",
    "\"\"\"\n",
    "\n",
    "#ratings_df = ratings_df.drop('timestamp')\n",
    "ratings_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load movies\n",
    "movies_df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|      1|Rogue One / Star ...|\n",
      "|      2|          Fight Club|\n",
      "|      3|   Lord of the Rings|\n",
      "|      4|              Trolls|\n",
      "|      5|       Despicable Me|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In order to determine the best ALS parameters, we will use the small dataset. \n",
    "We need first to split it into train, validation, and test datasets.\n",
    "\"\"\"\n",
    "(trainingData,validationData,testData) = ratings_df.randomSplit([0.6,0.2,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare test and validation set. They should not have ratings\n",
    "\n",
    "validation_for_predict = validationData.select('userId','movieId')\n",
    "test_for_predict = testData.select('userId','movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spark MLlib library for Machine Learning provides a Collaborative Filtering implementation by \n",
    "using Alternating Least Squares. The implementation in MLlib has the following parameters:\n",
    "\n",
    "    1. numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "    2. rank is the number of latent factors in the model.\n",
    "    3. iterations is the number of iterations to run.\n",
    "    4. lambda specifies the regularization parameter in ALS.\n",
    "    5. implicitPrefs specifies whether to use the explicit \n",
    "        feedback ALS variant or one adapted for implicit feedback data.\n",
    "    6. alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline \n",
    "        confidence in preference observations.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "seed = 5 #Random seed for initial matrix factorization model. A value of None will use system time as the seed.\n",
    "iterations = 10\n",
    "regularization_parameter = 0.01 #run for different lambdas - e.g. 0.01\n",
    "ranks = [4, 8, 12] #number of features\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 1.75254044445\n",
      "For rank 8 the RMSE is 1.8182110736\n",
      "For rank 12 the RMSE is 1.34319667706\n",
      "The best model was trained with rank 12\n"
     ]
    }
   ],
   "source": [
    "# Let us traing our dataset and check the best rank with lowest RMSE\n",
    "# predictAll method of the ALS takes only RDD format and hence we need to convert our dataframe into RDD\n",
    "# df.rdd will automatically converts Dataframe into RDD\n",
    "\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingData, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict.rdd).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validationData.rdd.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) # RMSE Error\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print ('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print ('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 1.94327935771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe best part is we do not have to worry about RDD any more with this library\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Spark will soon deprecate MLLIb package. \n",
    "They are focusing more on ML packages with standard machine learning implementation\n",
    "Let's see that package also\n",
    "\"\"\"\n",
    "als =  mlals(maxIter=iterations,rank=4,seed=seed,regParam=regularization_parameter, userCol=\"userId\", itemCol=\"movieId\",ratingCol=\"rating\")\n",
    "modelML = als.fit(trainingData)\n",
    "pred = modelML.transform(validationData)\n",
    "pred = pred.where(pred['prediction'] != 'NaN')\n",
    "    \n",
    "# Evaluate the model by computing RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(pred)\n",
    "\n",
    "print 'RMSE is %s' % rmse\n",
    "\n",
    "\"\"\"\n",
    "The best part is we do not have to worry about RDD any more with this library\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's take test dataset and get ratings\n",
    "predictions_test = model.predictAll(test_for_predict.rdd).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((200, 3), 3.5267400298734084),\n",
       " ((460, 7), 3.2325654969628546),\n",
       " ((240, 16), 3.8609647883036122)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## visualize preditions, here third element is predictions generated by ALS Model\n",
    "predictions_test.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's start recommending movies.\n",
    "I have written a method to call recommendations for a perticular user from test data\n",
    "\n",
    "TODO: You need to execute one more step before calling getRecommendations, \n",
    "      Think about that step. If you go through the seps below, you will realize it soon.\n",
    "\"\"\"\n",
    "def getRecommendations(user,testDf,trainDf,model):\n",
    "    # get all user and his/her rated movies\n",
    "    userDf = testDf.filter(testDf.userId == user)\n",
    "    # filter movies from main set which have not been rated by selected user\n",
    "    # and pass it to model we sreated above\n",
    "    mov = trainDf.select('movieId').subtract(userDf.select('movieId'))\n",
    "    \n",
    "    # Again we need to covert our dataframe into RDD\n",
    "    pred_rat = model.predictAll(mov.rdd.map(lambda x: (user, x[0]))).collect()\n",
    "    \n",
    "    # Get the top recommendations\n",
    "    recommendations = sorted(pred_rat, key=lambda x: x[2], reverse=True)[:50]\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies recommended for:269\n"
     ]
    }
   ],
   "source": [
    "# Assign user id for which we need recommendations\n",
    "user = 269\n",
    "\n",
    "# Call getRecommendations method\n",
    "derived_rec = getRecommendations(user,testData,trainingData,model)\n",
    "\n",
    "print (\"Movies recommended for:%d\" % user)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=269, product=11, rating=4.986591823580024),\n",
       " Rating(user=269, product=5, rating=4.821455620610955),\n",
       " Rating(user=269, product=1, rating=4.566817616998074),\n",
       " Rating(user=269, product=12, rating=4.413941354854723),\n",
       " Rating(user=269, product=8, rating=4.3757624175676),\n",
       " Rating(user=269, product=7, rating=4.244668235527135),\n",
       " Rating(user=269, product=14, rating=4.036707005084119),\n",
       " Rating(user=269, product=20, rating=4.001234231546155),\n",
       " Rating(user=269, product=21, rating=4.000386830223012),\n",
       " Rating(user=269, product=9, rating=3.851294238452813),\n",
       " Rating(user=269, product=13, rating=3.7756791741228763),\n",
       " Rating(user=269, product=18, rating=3.7467457425398494),\n",
       " Rating(user=269, product=6, rating=3.478718947169999),\n",
       " Rating(user=269, product=10, rating=3.4291735302826583),\n",
       " Rating(user=269, product=19, rating=3.204040969202517),\n",
       " Rating(user=269, product=15, rating=3.03762330633538),\n",
       " Rating(user=269, product=17, rating=3.0011408345368658)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "+-----------------+\n",
      "|            title|\n",
      "+-----------------+\n",
      "|Lord of the Rings|\n",
      "+-----------------+\n",
      "\n",
      "2\n",
      "+-------------+\n",
      "|        title|\n",
      "+-------------+\n",
      "|Despicable Me|\n",
      "+-------------+\n",
      "\n",
      "3\n",
      "+------------+\n",
      "|       title|\n",
      "+------------+\n",
      "|Pretty woman|\n",
      "+------------+\n",
      "\n",
      "4\n",
      "+---------+\n",
      "|    title|\n",
      "+---------+\n",
      "|Godfather|\n",
      "+---------+\n",
      "\n",
      "5\n",
      "+------+\n",
      "| title|\n",
      "+------+\n",
      "|Trolls|\n",
      "+------+\n",
      "\n",
      "6\n",
      "+---------+\n",
      "|    title|\n",
      "+---------+\n",
      "|Lala Land|\n",
      "+---------+\n",
      "\n",
      "7\n",
      "+------------------+\n",
      "|             title|\n",
      "+------------------+\n",
      "|500 days of Summer|\n",
      "+------------------+\n",
      "\n",
      "8\n",
      "+--------+\n",
      "|   title|\n",
      "+--------+\n",
      "|Hangover|\n",
      "+--------+\n",
      "\n",
      "9\n",
      "+---------------+\n",
      "|          title|\n",
      "+---------------+\n",
      "|Captain America|\n",
      "+---------------+\n",
      "\n",
      "10\n",
      "+-----+\n",
      "|title|\n",
      "+-----+\n",
      "| Kubo|\n",
      "+-----+\n",
      "\n",
      "11\n",
      "+------------+\n",
      "|       title|\n",
      "+------------+\n",
      "|Ghostbusters|\n",
      "+------------+\n",
      "\n",
      "12\n",
      "+------------+\n",
      "|       title|\n",
      "+------------+\n",
      "|Pulp Fiction|\n",
      "+------------+\n",
      "\n",
      "13\n",
      "+-------------+\n",
      "|        title|\n",
      "+-------------+\n",
      "|Almost Famous|\n",
      "+-------------+\n",
      "\n",
      "14\n",
      "+--------------+\n",
      "|         title|\n",
      "+--------------+\n",
      "|Hidden Figures|\n",
      "+--------------+\n",
      "\n",
      "15\n",
      "+-----+\n",
      "|title|\n",
      "+-----+\n",
      "| Sing|\n",
      "+-----+\n",
      "\n",
      "16\n",
      "+----------+\n",
      "|     title|\n",
      "+----------+\n",
      "|Fight Club|\n",
      "+----------+\n",
      "\n",
      "17\n",
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|Rogue One / Star ...|\n",
      "+--------------------+\n",
      "\n",
      "18\n",
      "+----------------+\n",
      "|           title|\n",
      "+----------------+\n",
      "|The big Lebowski|\n",
      "+----------------+\n",
      "\n",
      "19\n",
      "+---------+\n",
      "|    title|\n",
      "+---------+\n",
      "|Moonlight|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "# TODO: we can convert derived_rec into a dataframe to present it properly\n",
    "for i in xrange(len(derived_rec)):\n",
    "    print i+1\n",
    "    movies_df.filter(movies_df.movieId==derived_rec[i][1]).select('title').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
